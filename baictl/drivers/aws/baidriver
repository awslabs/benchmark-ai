#!/bin/bash

print_unsupported_verb() {
    local object=$1
    local verb=$2
    printf "Unsupported verb ${verb} for object ${object}\n"
}

_create_configmap_yaml_from_terraform_outputs() {
    local outputs=$(terraform output -json)
    local configmap_data=""
    for row in $(echo "${outputs}" | jq -r 'to_entries | .[] | @base64'); do
        # Use base64 because the output might contain a \n, which will break this whole loop
        _jq() {
            echo ${row} | base64 --decode | jq -r ${1}
        }

        key=$(_jq '.key')
        value=$(_jq '.value.value')
        sensitive=$(_jq '.value.sensitive')
        # Avoid sensitive and values with newlines
        if [[ ($sensitive == "false") && ("$value" != *$'\n'*) ]]; then
            configmap_data="$configmap_data\n  $key: $value"
        fi
    done

    # printf => To interpret the \n symbols in the variable
    # tail => To skip the first line, which should be empty
    configmap_data=$(printf "$configmap_data" | tail -n +2)

cat << EOF
apiVersion: v1
data:
$configmap_data
kind: ConfigMap
metadata:
  name: outputs-infrastructure
EOF
}

create_infra() {
    local cluster_name=""
    local region=""
    local prefix_list_id=""
    local validate=true

    for arg in "$@"; do
        case "${arg}" in
        --name=*)
            cluster_name="${arg#*=}"
            ;;
        --aws-region=*)
            region="${arg#*=}"
            ;;
        --aws-prefix-list-id=*)
            prefix_list_id="${arg#*=}"
            ;;
        --no-validate)
            validate=false
            ;;
        esac
    done

    #Temporary behavior
    [ -z "$prefix_list_id" ] && printf "Missing required argument --aws-prefix-list-id\n" && return 1

    _install_msk_aware_terraform_plugin || return 1

    cd $data_dir

    local vars=""

    [[ -n "$cluster_name" ]] && vars="${vars} -var cluster_name=${cluster_name}"
    [[ -n "$region" ]] && vars="${vars} -var region=${region}"
    [[ -n "$prefix_list_id" ]] && vars="${vars} -var prefix_list_ids=[\"${prefix_list_id}\"]"

    _initialize_terraform_backend || return 1

    terraform plan --state=$terraform_state --out=$terraform_plan ${vars} $terraform_dir || return 1
    terraform apply $terraform_plan || return 1
    terraform output kubectl_config >kubeconfig || return 1

    $kubectl apply -f fluentd-daemonset.yaml
    $kubectl apply -f autoscaler-deployment.yaml

    $kubectl apply -f https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/v1.11/nvidia-device-plugin.yml
    $kubectl apply -f $project_dir/metrics-pusher/metrics-pusher-roles.yaml
    $kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/master/aio/deploy/recommended/kubernetes-dashboard.yaml

    _create_configmap_yaml_from_terraform_outputs | $kubectl apply -f -

    _install_kubeflow_operators || return 1
    _create_kafka_topics || return 1

    _install_zookeeper || return 1

    [ "$validate" == false ] || validate_infra $@
}

_initialize_terraform_backend(){
    if [[ ! -f $data_dir/backend.tfvars ]] ; then
        printf "Creating bootstrap S3 bucket...\n"
        local uuid=$(uuidgen | tr '[:upper:]' '[:lower:]')
        aws s3 mb s3://terraform-state-$uuid || return 1
        cat <<-END > backend.tfvars
        bucket="terraform-state-${uuid}"
        key="terraform.tfstate"
        region="eu-west-1"
END
    fi
    # Get bucket name from backend.tfvars
    local s3_bucket_name=$(awk -F'"' 'NR==1{print $2}'  $data_dir/backend.tfvars)
    if ! aws s3 ls s3://$s3_bucket_name; then
        printf "S3 bucket in $data_dir/backend.tfvars does not exist!\n"
        return 1
    fi
    terraform init --backend-config=$data_dir/backend.tfvars $terraform_dir
    terraform get $terraform_dir
}

_install_msk_aware_terraform_plugin(){
    # Get Kafka AWS binary and put it in terraform plugins directory
    local plugin_name="terraform-provider-aws_v2.4.0"
    local kernel=$(uname | awk '{print tolower($0)}')
    local s3_key=s3://benchmark-ai/${kernel}/${plugin_name}
    if [[ ! -f ~/.terraform.d/plugins/${plugin_name} ]] ; then
        printf 'Downloading MSK-aware aws terraform plugin binary...\n'
        mkdir -p ~/.terraform.d/plugins
        if aws s3 cp "$s3_key" ~/.terraform.d/plugins; then
            chmod +x ~/.terraform.d/plugins/${plugin_name}
        else
            CANONICAL_ID=$(aws s3api list-buckets --output json | jq --raw-output  '.Owner.ID')
            printf "Please add your account ID: %s RO permissions to %s in mxnet-edge-bln account\n" "$CANONICAL_ID" "${s3_key}"
            return 1
        fi
    fi
}


_create_kafka_topics(){
    local msk_zookeeper_connect=$(terraform output --state=$terraform_state msk_zookeeper_connect)
    local bastion_pem_filename=$(terraform output --state=$terraform_state bastion_pem_filename)
    local bastion_public_ip=$(terraform output --state=$terraform_state bastion_public_ip)
    local kafka_topics=("BAI_APP_BFF" "BAI_APP_FETCHER" "BAI_APP_EXECUTOR" "BAI_SYS_BFF" "BAI_SYS_FETCHER" "BAI_SYS_EXECUTOR" "CMD_SUBMIT" "CMD_RETURN")

    printf "Creating Kafka Topics...\n"
    for topic in "${kafka_topics[@]}"; do
        ssh -i ${data_dir}/${bastion_pem_filename} -t ubuntu@$bastion_public_ip -o StrictHostKeyChecking=no "/snap/bin/kafka.topics --create --if-not-exists --zookeeper $msk_zookeeper_connect --replication-factor 3 --partitions 1 --topic $topic"
    done

}

__create_kubeflow_namespace(){
    cat << EOF
apiVersion: v1
kind: Namespace
metadata:
  name: kubeflow
EOF
}

_install_kubeflow_operators() {
    if [ ! -d "kubeflow-ks-app" ]; then
        (
            mkdir kubeflow-ks-app
            cd kubeflow-ks-app || return 1

            export KUBECONFIG=$kubeconfig
            ks init ks_app

            cd ks_app || return 1

            __create_kubeflow_namespace | kubectl apply -f -

            ks registry add kubeflow https://github.com/kubeflow/kubeflow/tree/v0.4.1/kubeflow && \
            ks env add kubeflow --namespace "$kubeflow_namespace" && \
            ks pkg install kubeflow/mpi-job && \
            ks pkg install kubeflow/mxnet-job && \
            ks generate mpi-operator mpi-operator && \
            ks generate mxnet-operator mxnet-operator || \
            return 1
        )
    fi
    
    (
        export KUBECONFIG=$kubeconfig
        cd kubeflow-ks-app/ks_app || return 1
        ks apply kubeflow --component mpi-operator && \
        ks apply kubeflow --component mxnet-operator || \
        return 1
    )
}

_install_zookeeper(){
    $kubectl apply -f $k8s_deploy_dir/zookeeper.yaml || return 1
}

destroy_infra() {
     for arg in "$@"; do
        case "${arg}" in
        --aws-region=*)
            region="${arg#*=}"
            ;;
        esac
    done

    cd $data_dir

    [ -n "$region" ] && vars="${vars} -var region=${region}"

    _initialize_terraform_backend || return 1
    terraform destroy --state=$terraform_state -auto-approve ${vars} $terraform_dir
}

get_infra() {
    for arg in "$@"; do
        printf "\n----------\n"
        case "${arg}" in
        --nodes)
            $kubectl get nodes -o wide
            ;;
        --aws-es)
            terraform output --state=$terraform_state es_endpoint
            ;;
        --aws-cluster)
            terraform output --state=$terraform_state region
            terraform output --state=$terraform_state cluster_name
            terraform output --state=$terraform_state cluster_endpoint
            ;;
        --aws-bastion-ip)
            terraform output --state=$terraform_state bastion_public_ip
            ;;
        esac
    done
    printf "\n----------\n"
}

__validate_crd(){
    local type=$1
    local namespace=$2

    local kind
    kind=$($kubectl get crd "${type}" --namespace "${namespace}" --output=json | jq .kind --raw-output)
    [ "$kind" == "CustomResourceDefinition" ] || return 1
}

__validate_mpi_job(){
    printf "MPI Job is present"
    __validate_crd mpijobs.kubeflow.org "$kubeflow_namespace"
}

__validate_mxnet_job(){
    printf "MXNET Job is present"
    __validate_crd mxjobs.kubeflow.org "$kubeflow_namespace"
}

__validate_kafka_topics(){
    printf "Kafka Topics are present"
    local msk_zookeeper_connect=$(terraform output --state=$terraform_state msk_zookeeper_connect)
    local bastion_pem_filename=$(terraform output --state=$terraform_state bastion_pem_filename)
    local bastion_public_ip=$(terraform output --state=$terraform_state bastion_public_ip)
    local result=$(ssh -i ${data_dir}/${bastion_pem_filename} -t ubuntu@$bastion_public_ip -o StrictHostKeyChecking=no -o LogLevel=QUIET "/snap/bin/kafka.topics --list --zookeeper $msk_zookeeper_connect")
    local kafka_topics=("BAI_APP_BFF" "BAI_APP_FETCHER" "BAI_APP_EXECUTOR" "BAI_SYS_BFF" "BAI_SYS_FETCHER" "BAI_SYS_EXECUTOR" "CMD_SUBMIT" "CMD_RETURN")

    for topic in "${kafka_topics[@]}"; do
        echo $result | grep $topic > /dev/null || return 1 
    done
}

__validate_zookeeper_pods(){
    printf "ZooKeeper is ready"
    $kubectl wait --for=condition=ready pod --selector=app=zookeeper --timeout=300s > /dev/null || return 1
}

validate_infra(){
    local all_ok=true

    local rules=(__validate_mpi_job __validate_mxnet_job __validate_kafka_topics __validate_zookeeper_pods)

    for rule in "${rules[@]}"; do
        local result=true
        eval "$rule" || result=false

        printf "..."

        [ "$result" == false ] && printf "FAILED\n" && all_ok=false || printf "PASSED\n"
    done
    [ "$all_ok" == true ] || return 1
}

get_benchmark() {
    local benchmark_name=""

    for arg in "$@"; do
        case "${arg}" in
        --name=*)
            benchmark_name="${arg#*=}"
            ;;
        --aws-es-page-size=*)
            page_size="${arg#*=}"
            ;;
        esac
    done

    [ -z "$benchmark_name" ] && printf "Missing required argument --name\n" && return 1
    [ -z "$page_size" ] && page_size=10000

    bastion_pem_filename=$(terraform output --state=$terraform_state bastion_pem_filename)
    bastion_ip=$(terraform output --state=$terraform_state bastion_public_ip)
    es_endpoint=$(terraform output --state=$terraform_state es_endpoint)

    _call_elasticsearch() {
        local url=${1}
        local query_body=${2}
        local curl_cmd="curl -X POST -s -H 'Content-Type: application/json' -d '$query_body' ${es_endpoint}/${url}"
        local result=$(ssh -q -o StrictHostKeyChecking=no -i ${data_dir}/${bastion_pem_filename} ubuntu@${bastion_ip} "${curl_cmd}")
        local status=$(echo $result | jq '.status')
        if [[ "$status" -ne "null" ]]; then
            echo "==========================================================================================" >&2
            echo "Error calling elasticsearch on '${url}'. Got status '${status}'" >&2
            echo "Body of query is:" >&2
            echo ${query_body} >&2
            echo "See output for details:" >&2
            echo $result | jq >&2
            echo "==========================================================================================" >&2
            exit 1
        fi
        echo $result
    }

    local current_page_filename=$(mktemp /tmp/bai-current-page.XXXXXX.json)
    # See the "trap" trick: https://stackoverflow.com/questions/687014/removing-created-temp-files-in-unexpected-bash-exit
    trap "{ rm -f $current_page_filename; }" EXIT

    # Use the "scroll" api from Elasticsearch to do pagination
    # see: https://www.elastic.co/guide/en/elasticsearch/reference/6.4/search-request-scroll.html
    local search_query=$(cat <<-END
        {
            "size" : $page_size,
            "query" : {
                "term" : { "kubernetes.labels.job-name":"$benchmark_name" }
            },
            "sort": [
                {"@timestamp": {"order": "asc"}}
            ]
        }
END
)
    _call_elasticsearch "_search?scroll=1m" "${search_query}" > $current_page_filename

    local scroll_id=$(cat $current_page_filename | jq '._scroll_id')

    while true; do
        local current_page_size=$(cat $current_page_filename | jq '.hits.hits | length')
        if [[ ${current_page_size} == 0 ]];  then
            break
        fi

        # Print the logs
        cat $current_page_filename | jq '.hits.hits[]._source | "(\(."@timestamp") \(.log)"' -j

        # Fetch next page
        local next_page_query="{\"scroll\" : \"1m\", \"scroll_id\" : $scroll_id}"
        _call_elasticsearch "_search/scroll" "${next_page_query}" > $current_page_filename
    done
}

run_benchmark() {
    local descriptor=""

    for arg in "$@"; do
        case "${arg}" in
        --descriptor=*)
            descriptor="${arg#*=}"
            ;;
        esac
    done

    [ -z "$descriptor" ] && printf "Missing required argument --descriptor\n" && return 1

    export PYTHONPATH=$(dirname $BASH_SOURCE)/../../descriptor-file/src
    local azs=$(terraform output -json --state=$terraform_state availability_zones | jq -r '.value | join(" ")')
    python3 $(dirname $BASH_SOURCE)/../../descriptor-file/src/transpiler/__main__.py $(pwd)/$descriptor --availability-zones $azs | $kubectl apply -f -
}

delete_benchmark() {
    local benchmark_name=""
    local all=""

    for arg in "$@"; do
        case "${arg}" in
        --all)
            all="1"
            ;;
        --name=*)
            benchmark_name="${arg#*=}"
            ;;
        esac
    done

    [ -n "$all" ] && benchmark_name="--all"
    [ -z "$benchmark_name" ] && printf "Missing required argument --name or --all\n" && return 1

    $kubectl delete job $benchmark_name
}

list_benchmarks() {
    $kubectl get jobs --selector app=benchmark-ai -o wide
}

schedule_benchmark() {
    printf "Not yet implemented\n"
}

show_k8s_dashboard() {
    echo "The Kubernetes dashboard will be available in http://localhost:8001/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/"
    ${kubectl} proxy
}

verb=$1
object=$2

shift
shift

verbose=""
data_dir=${HOME}/.bai

#Common args
for arg in "$@"; do
    case "${arg}" in
    --data-dir=*)
        data_dir="${arg#*=}"
        ;;
    --verbose)
        verbose="1"
        ;;
    esac
done

[ ! -d "$data_dir" ] && mkdir $data_dir

data_dir=$(realpath $data_dir)
kubeconfig=$(realpath $data_dir/kubeconfig)
kube_config_arg=--kubeconfig=$kubeconfig
kubectl="kubectl ${kube_config_arg}"
terraform_state=$data_dir/terraform.tfstate
terraform_state_arg=--state=$data_dir/terraform.tfstate
terraform_dir=$(dirname $BASH_SOURCE)/cluster
terraform_plan=$data_dir/terraform.plan

terraform_dir=$(realpath $terraform_dir)
terraform_state=$(realpath $terraform_state)
terraform_plan=$(realpath $terraform_plan)

project_dir=$(realpath $(dirname $BASH_SOURCE)/../../..)
k8s_deploy_dir=$(realpath $(dirname $BASH_SOURCE))/deploy

readonly kubeflow_namespace=kubeflow

case "${object}" in
infra)

    case "${verb}" in
    create)
        create_infra $@
        ;;
    destroy)
        destroy_infra $@
        ;;
    get)
        get_infra $@
        ;;
    validate)
        validate_infra $@
        ;;
    *)
        print_unsupported_verb $object $verb
        ;;
    esac

    ;;
benchmark)

    case "${verb}" in
    run)
        run_benchmark $@
        ;;
    schedule)
        schedule_benchmark $@
        ;;
    get)
        get_benchmark $@
        ;;
    delete)
        delete_benchmark $@
        ;;
    list)
        list_benchmarks $@
        ;;
    *)
        print_unsupported_verb $object $verb
        ;;
    esac
    ;;

k8s-dashboard)

    case "${verb}" in
	show)
	    show_k8s_dashboard $@
	    ;;

	*)
        print_unsupported_verb $object $verb
        ;;
    esac
    ;;

*)
    printf "Unknown object"
    ;;
esac
