#!/bin/bash

print_unsupported_verb() {
    local object=$1
    local verb=$2
    printf "Unsupported verb ${verb} for object ${object}\n"
}

_create_configmap_yaml_from_terraform_outputs() {
    local bash_src=$(realpath ${BASH_SOURCE})
    local src_dir=$(dirname "${bash_src}")
    (
        export KUBECONFIG=${kubeconfig}
        python3 ${src_dir}/add_terraform_outputs_as_configmap.py outputs-infrastructure || return 1
    )
}

create_infra() {
    local cluster_name=""
    local prefix_list_id=""
    local ssh_access_cidr_blocks=""
    local validate=true

    for arg in "$@"; do
        case "${arg}" in
        --name=*)
            cluster_name="${arg#*=}"
            ;;
        --aws-region=*)
            region="${arg#*=}"
            ;;
        --aws-prefix-list-id=*)
            prefix_list_id="${arg#*=}"
            ;;
        --aws-ssh-access-cidr-blocks=*)
            ssh_access_cidr_blocks="${arg#*=}"
            ;;
        --no-validate)
            validate=false
            ;;
        esac
    done

    #Temporary behavior
    [ -z "$prefix_list_id" ] && printf "Missing required argument --aws-prefix-list-id\n" && return 1
    [ -z "$region" ] && printf "Missing required argument --aws-region\n" && return 1

    _install_msk_aware_terraform_plugin || return 1

    cd $terraform_dir

    local vars=""

    [[ -n "$cluster_name" ]] && vars="${vars} -var cluster_name=${cluster_name}"
    [[ -n "$region" ]] && vars="${vars} -var region=${region}"
    [[ -n "$prefix_list_id" ]] && vars="${vars} -var prefix_list_ids=[\"${prefix_list_id}\"]"
    [[ -n "$ssh_access_cidr_blocks" ]] && vars="${vars} -var ssh_access_cidr_blocks=[\"${ssh_access_cidr_blocks}\"]"

    echo "==> Initializing terraform"
    _initialize_terraform_backend ${region} || return 1

    echo "==> Calling terraform plan with ${vars}"
    terraform plan --out=$terraform_plan -var data_dir=$data_dir ${vars} || return 1
    terraform apply $terraform_plan || return 1

    terraform output kubectl_config > $kubeconfig || return 1

    echo "==> Creating Kubernetes objects"
    ${kubectl} apply -f $data_dir/fluentd-daemonset.yaml
    ${kubectl} apply -f $data_dir/autoscaler-deployment.yaml

    ${kubectl} apply -f https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/v1.11/nvidia-device-plugin.yml
    ${kubectl} apply -f $project_dir/metrics-pusher/metrics-pusher-roles.yaml
    ${kubectl} apply -f https://raw.githubusercontent.com/kubernetes/dashboard/master/aio/deploy/recommended/kubernetes-dashboard.yaml

    echo "==> Adding permission for CodeBuild role to deploy into the Kubernetes cluster"
    _add_codebuild_role || return 1

    echo "==> Creating configmap from Terraform outputs"
    _create_configmap_yaml_from_terraform_outputs || return 1

    echo "==> Installing kubeflow operators"
    _install_kubeflow_operators || return 1

    echo "==> Creating Kafka topics"
    _create_kafka_topics || return 1

    echo "==> Installing Tiller"
    _install_tiller || return 1

    echo "==> Installing Prometheus"
    _install_prometheus || return 1

    echo "==> Installing zookeeper"
    _install_zookeeper || return 1

    echo "==> Validating infrastructure"
    [[ "$validate" == false ]] || validate_infra $@
}

_initialize_terraform_backend() {
    local region=$1
    if [[ ! -f ${data_dir}/backend.tfvars ]] ; then
        local account_id=$(aws sts get-caller-identity | jq -r '.Account') || return 1
        local bucket="bai-terraform-state-${region}-${account_id}"

        if aws s3 ls s3://$bucket; then
            printf "S3 bucket in $data_dir/backend.tfvars already exists. Only creating backend.tfvars file\n"
        else
            printf "Creating bootstrap S3 bucket...\n"
            aws s3 mb s3://${bucket} --region ${region} || return 1
        fi
        cat <<-END > ${data_dir}/backend.tfvars
        bucket="${bucket}"
        key="terraform.tfstate"
        region="${region}"
END
    fi
    # Get bucket name from backend.tfvars
    local s3_bucket_name=$(cat $data_dir/backend.tfvars | grep bucket | awk -F'"' '{print $2}')
    if [[ "$s3_bucket_name" == "" ]] || ! aws s3 ls s3://${s3_bucket_name}; then
        printf "S3 bucket ($s3_bucket_name) in $data_dir/backend.tfvars does not exist!\n"
        return 1
    fi
    echo "-> Calling terraform init"
    terraform init --backend-config=${data_dir}/backend.tfvars || return 1
    echo "-> Calling terraform get"
    terraform get || return 1
}

_install_msk_aware_terraform_plugin(){
    # Get Kafka AWS binary and put it in terraform plugins directory
    local plugin_zip="terraform-provider-aws_v2.4.0.zip"
    local plugin_name="terraform-provider-aws_v2.4.0"
    local kernel=$(uname | awk '{print tolower($0)}')
    local plugin_url="https://chancebair.github.io/terraform-msk-binaries/${kernel}/${plugin_zip}"
    if [[ ! -f ~/.terraform.d/plugins/${plugin_name} ]] ; then
        printf 'Downloading MSK-aware aws terraform plugin binary...\n'
        mkdir -p ~/.terraform.d/plugins
        if wget -nv -P ~/.terraform.d/plugins ${plugin_url} ; then
            unzip ~/.terraform.d/plugins/${plugin_zip} -d ~/.terraform.d/plugins/
            chmod +x ~/.terraform.d/plugins/${plugin_name}
        else
            printf "Failed to download MSK plugin zip file from $plugin_url\n"
            return 1
        fi
    fi
}

_install_tiller(){
    ${kubectl} get serviceaccount -n ${tiller_namespace} tiller -o yaml || $kubectl create serviceaccount --namespace ${tiller_namespace} tiller || return 1
    ${kubectl} get clusterrolebinding tiller-cluster-rule -o yaml || $kubectl create clusterrolebinding tiller-cluster-rule --clusterrole=cluster-admin --serviceaccount=${tiller_namespace}:tiller || return 1

    ${helm} init --wait --service-account tiller || return 1
    #TODO: Secure through TLS?: https://github.com/jonbcampos/kubernetes-series/blob/master/helm/scripts/add_secure_helm.sh
    # TODO: Permissions RBAC
    # https://medium.com/@amimahloof/how-to-setup-helm-and-tiller-with-rbac-and-namespaces-34bf27f7d3c3
}

_install_prometheus(){
    ${helm} upgrade --install prometheus-operator-1 -f ${k8s_deploy_dir}/prometheus-operator.yaml stable/prometheus-operator || return 1
}

port_forward() {
    local service_name=""
    for arg in "$@"; do
        case "${arg}" in
        --service=*)
            service_name="${arg#*=}"
            ;;
        esac
    done

    if [ -z "$service_name" ]; then
        printf "Missing required argument --service=[grafana|alertmanager|prometheus]\n" && return 1
    fi

    if [ "$service_name" == "grafana" ]; then
        _port_forward_grafana
    elif [ "$service_name" == "alertmanager" ]; then
        _port_forward_alertmanager
    elif [ "$service_name" == "prometheus" ]; then
        _port_forward_prometheus
    else
        printf "Unknown service $service_name\n" && return 1
    fi
}

_port_forward_grafana(){
    printf "Navigate to 127.0.0.1:3000 to access the Grafana dashboard\nCtrl+C to cancel the session.\n"
    ${kubectl} port-forward deployment/prometheus-operator-1-grafana 3000
}

_port_forward_alertmanager(){
    printf "Navigate to 127.0.0.1:9093 to access the AlertManager dashboard\nCtrl+C to cancel the session.\n"
    ${kubectl} port-forward alertmanager-prometheus-operator-1-alertmanager-0 9093
}

_port_forward_prometheus(){
    printf "Navigate to 127.0.0.1:9090 to access the Prometheus dashboard\nCtrl+C to cancel the session.\n"
    ${kubectl} port-forward prometheus-prometheus-operator-1-prometheus-0 9090
}

_create_kafka_topics(){
    local outputs=$(terraform output -json)
    local msk_zookeeper_connect=$(echo $outputs | jq -r '.msk_zookeeper_connect.value')
    local bastion_pem_filename=$(echo $outputs | jq -r '.bastion_pem_filename.value')
    local bastion_public_ip=$(echo $outputs | jq -r '.bastion_public_ip.value')

    printf "Creating Kafka Topics...\n"
    for topic in "${kafka_topics[@]}"; do
        echo "---- Topic: ${topic}..."
        ssh -i ${bastion_pem_filename} -t ubuntu@$bastion_public_ip -o StrictHostKeyChecking=no "/snap/bin/kafka.topics --create --if-not-exists --zookeeper $msk_zookeeper_connect --replication-factor 3 --partitions 1 --topic $topic"
        echo "---- Topic: ${topic}... DONE"
    done

}

_add_codebuild_role(){
    local account_id=$(aws sts get-caller-identity | jq -r '.Account') || return 1

    local bash_src=$(realpath ${BASH_SOURCE})
    local src_dir=$(dirname "${bash_src}")
    (
        export KUBECONFIG=${kubeconfig}
        python3 ${src_dir}/add_permission_to_aws_auth_configmap.py --role-arn "arn:aws:iam::${account_id}:role/code-build-role" --role-username build --role-groups system:masters || return 1
    )
}

__create_kubeflow_namespace(){
    cat << EOF
apiVersion: v1
kind: Namespace
metadata:
  name: kubeflow
EOF
}

_install_kubeflow_operators() {
    if [[ ! -d "$data_dir/kubeflow-ks-app" ]]; then
    (
        mkdir $data_dir/kubeflow-ks-app
        cd $data_dir/kubeflow-ks-app

        export KUBECONFIG=$kubeconfig
        ks init ks_app

        cd ks_app || return 1

        echo "-> Creating kubeflow namespace"
        __create_kubeflow_namespace | ${kubectl} apply -f -

        echo "-> Applying kubeflow stuff"
        ks registry add kubeflow https://github.com/kubeflow/kubeflow/tree/v0.4.1/kubeflow && \
            ks env add kubeflow --namespace "$kubeflow_namespace" && \
            ks pkg install kubeflow/mpi-job && \
            ks pkg install kubeflow/mxnet-job && \
            ks generate mpi-operator mpi-operator && \
            ks generate mxnet-operator mxnet-operator
        local exit_code=$?
        [[ "$exit_code" != 0 ]] && echo "[ERROR] Failed with exit code: $exit_code" && return 1
    )
    fi

    echo "-> Kubeflow should be already installed, re-applying configuration"
    (
    export KUBECONFIG=$kubeconfig
    cd $data_dir/kubeflow-ks-app/ks_app
    ks apply kubeflow --component mpi-operator && \
        ks apply kubeflow --component mxnet-operator
    local exit_code=$?
    [[ "$exit_code" != 0 ]] && echo "[ERROR] Failed with exit code: $exit_code" && return 1
    )

    return 0
}

_init_service_account() {
    echo "-> Initializing service account for helm"
    ${kubectl} apply -f ${project_dir}/baictl/helm/
}

_init_helm() {
    _init_service_account || return 1
    ${helm} init --upgrade --history-max 200 --wait --service-account tiller || return 1
    echo "-> Updating helm"
    ${helm} repo update || return 1
}

_install_grafana() {
    ${helm} upgrade --install grafana \
        --namespace ${tiller_namespace} \
        --set rbac.pspEnabled=false \
        --set rbac.create=false \
        --set service.type=LoadBalancer \
        --wait \
        stable/grafana || return 1
}

_destroy_helm_charts() {
    echo "-> Destroying helm charts:\n$(helm ls --short)\n"
    ${helm} delete $(${helm} ls --short) --purge || return 1

    # TODO: `helm delete` does not properly delete CRDs which are created by the Prometheus Operator, for example:
    # https://github.com/istio/istio/issues/7688
}

_install_zookeeper(){
    ${kubectl} apply -f ${k8s_deploy_dir}/zookeeper.yaml || return 1
}

destroy_infra() {
    for arg in "$@"; do
        case "${arg}" in
        --aws-region=*)
            region="${arg#*=}"
            ;;
        esac
    done

    cd ${terraform_dir}

    if [[ -n "$region" ]]; then
        vars="${vars} -var region=${region} -var data_dir=${data_dir}"
    else
        printf "Missing required argument --aws-region\n" && return 1
    fi

    _install_msk_aware_terraform_plugin || return 1

    _initialize_terraform_backend ${region} || return 1
    terraform destroy -auto-approve ${vars}


}

get_infra() {
    cd $terraform_dir

    for arg in "$@"; do
        printf "\n----------\n"
        case "${arg}" in
        --nodes)
            $kubectl get nodes -o wide
            ;;
        --aws-es)
            terraform output es_endpoint
            ;;
        --aws-cluster)
            terraform output region
            terraform output eks_cluster_name
            terraform output cluster_endpoint
            ;;
        --aws-bastion-ip)
            terraform output bastion_public_ip
            ;;
        esac
    done
    printf "\n----------\n"
}

__validate_crd() {
    local type=$1
    local namespace=$2

    local kind
    kind=$($kubectl get crd "${type}" --namespace "${namespace}" --output=json | jq .kind --raw-output)
    [[ "$kind" == "CustomResourceDefinition" ]] || return 1
}

__validate_mpi_job() {
    printf "MPI Job is present"
    __validate_crd mpijobs.kubeflow.org "$kubeflow_namespace"
}

__validate_mxnet_job() {
    printf "MXNET Job is present"
    __validate_crd mxjobs.kubeflow.org "$kubeflow_namespace"
}

__validate_kafka_topics() {
    printf "Kafka Topics are present"

    (
    cd $terraform_dir > /dev/null
    local outputs=$(terraform output -json)
    local msk_zookeeper_connect=$(echo $outputs | jq -r '.msk_zookeeper_connect.value')
    local bastion_pem_filename=$(echo $outputs | jq -r '.bastion_pem_filename.value')
    local bastion_public_ip=$(echo $outputs | jq -r '.bastion_public_ip.value')

    local result=$(ssh -i ${bastion_pem_filename} -t ubuntu@$bastion_public_ip -o StrictHostKeyChecking=no -o LogLevel=QUIET "/snap/bin/kafka.topics --list --zookeeper $msk_zookeeper_connect")

    for topic in "${kafka_topics[@]}"; do
        echo $result | grep $topic > /dev/null || return 1
    done
    )
}

__validate_zookeeper_pods() {
    printf "ZooKeeper is ready"
    $kubectl wait --for=condition=ready pod --selector=app=zookeeper --timeout=300s > /dev/null || return 1
}

__validate_grafana() {
    # TODO: Validate through tunnel method.
    # This method only works if the load balancer is up, which is complicated because it either has to be
    # restricted to Amzn (for example) which then makes it unavailable to ECS (if we don't deploy through our Macs)
    # or we have to use a public endpoint which has security concerns.

    printf "Grafana is ready"
    password=$(
        ${kubectl} get secret --namespace tiller-world grafana -o jsonpath="{.data.admin-password}" | base64 --decode
    )
    host=$(
        ${kubectl} get svc grafana --namespace tiller-world -o jsonpath='{.status.loadBalancer.ingress[0].hostname}'
    )

    # TODO: Determine security implications of this call. Generally we should avoid passing credentials as program args
    # according to https://coe.amazon.com/coes/100190
    curl http://admin:${password}@${host}:80/api/health || return 1
}

validate_infra() {
    local all_ok=true
    local rules=(
        __validate_mpi_job \
        __validate_mxnet_job \
        __validate_kafka_topics \
        __validate_zookeeper_pods
    )

    for rule in "${rules[@]}"; do
        local result=true
        eval "$rule" || result=false

        printf "..."

        [[ "$result" == false ]] && printf "FAILED\n" && all_ok=false || printf "PASSED\n"
    done

    [[ "$all_ok" == true ]] || return 1
}

get_benchmark() {
    local benchmark_name=""

    for arg in "$@"; do
        case "${arg}" in
        --name=*)
            benchmark_name="${arg#*=}"
            ;;
        --aws-es-page-size=*)
            page_size="${arg#*=}"
            ;;
        esac
    done

    [ -z "$benchmark_name" ] && printf "Missing required argument --name\n" && return 1
    [ -z "$page_size" ] && page_size=10000

    cd $terraform_dir

    bastion_pem_filename=$(terraform output bastion_pem_filename)
    bastion_ip=$(terraform output bastion_public_ip)
    es_endpoint=$(terraform output es_endpoint)

    _call_elasticsearch() {
        local url=${1}
        local query_body=${2}
        local curl_cmd="curl -X POST -s -H 'Content-Type: application/json' -d '$query_body' ${es_endpoint}/${url}"
        local result=$(ssh -q -o StrictHostKeyChecking=no -i ${bastion_pem_filename} ubuntu@${bastion_ip} "${curl_cmd}")
        local status=$(echo $result | jq '.status')
        if [[ "$status" -ne "null" ]]; then
            echo "==========================================================================================" >&2
            echo "Error calling elasticsearch on '${url}'. Got status '${status}'" >&2
            echo "Body of query is:" >&2
            echo ${query_body} >&2
            echo "See output for details:" >&2
            echo $result | jq >&2
            echo "==========================================================================================" >&2
            exit 1
        fi
        echo $result
    }

    local current_page_filename=$(mktemp /tmp/bai-current-page.XXXXXX.json)
    # See the "trap" trick: https://stackoverflow.com/questions/687014/removing-created-temp-files-in-unexpected-bash-exit
    trap "{ rm -f $current_page_filename; }" EXIT

    # Use the "scroll" api from Elasticsearch to do pagination
    # see: https://www.elastic.co/guide/en/elasticsearch/reference/6.4/search-request-scroll.html
    local search_query=$(cat <<-END
        {
            "size" : $page_size,
            "query" : {
                "term" : { "kubernetes.labels.job-name":"$benchmark_name" }
            },
            "sort": [
                {"@timestamp": {"order": "asc"}}
            ]
        }
END
)
    _call_elasticsearch "_search?scroll=1m" "${search_query}" > $current_page_filename

    local scroll_id=$(cat $current_page_filename | jq '._scroll_id')

    while true; do
        local current_page_size=$(cat $current_page_filename | jq '.hits.hits | length')
        if [[ ${current_page_size} == 0 ]];  then
            break
        fi

        # Print the logs
        cat $current_page_filename | jq '.hits.hits[]._source | "(\(."@timestamp") \(.log)"' -j

        # Fetch next page
        local next_page_query="{\"scroll\" : \"1m\", \"scroll_id\" : $scroll_id}"
        _call_elasticsearch "_search/scroll" "${next_page_query}" > $current_page_filename
    done
}

run_benchmark() {
    local descriptor=""

    for arg in "$@"; do
        case "${arg}" in
        --descriptor=*)
            descriptor="${arg#*=}"
            ;;
        esac
    done

    [ -z "$descriptor" ] && printf "Missing required argument --descriptor\n" && return 1

    (
        local bash_src=$(realpath ${BASH_SOURCE})
        local src_dir=$(dirname "${bash_src}")

        export PYTHONPATH=${src_dir}/../../../executor/src:${src_dir}/../../../kafka-utils/src

        pushd ${terraform_dir} > /dev/null
        local azs=$(terraform output -json --state=${terraform_state} availability_zones | jq -r '.value | join(" ")')
        popd

        [ -z "${azs}" ] && printf "Availability zones could not be identified from terraform state %s\n" "${terraform_state}" && return 1

        python3 ${src_dir}/../../../executor/src/transpiler/__main__.py --descriptor ${descriptor} --availability-zones ${azs} | ${kubectl} apply -f -
    )
}

delete_benchmark() {
    local benchmark_name=""
    local all=""

    for arg in "$@"; do
        case "${arg}" in
        --all)
            all="1"
            ;;
        --name=*)
            benchmark_name="${arg#*=}"
            ;;
        esac
    done

    [ -n "$all" ] && benchmark_name="--all"
    [ -z "$benchmark_name" ] && printf "Missing required argument --name or --all\n" && return 1

    $kubectl delete job $benchmark_name
}

list_benchmarks() {
    $kubectl get jobs --selector app=benchmark-ai -o wide
}

schedule_benchmark() {
    printf "Not yet implemented\n"
}

show_k8s_dashboard() {
    echo "The Kubernetes dashboard will be available in http://localhost:8001/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/"
    ${kubectl} proxy
}

verb=$1
object=$2

shift
shift

verbose=""
data_dir=${HOME}/.bai

#Common args
for arg in "$@"; do
    case "${arg}" in
    --data-dir=*)
        data_dir="${arg#*=}"
        ;;
    --verbose)
        verbose="1"
        ;;
    esac
done

mkdir -p ${data_dir}

data_dir=$(realpath ${data_dir})
kubeconfig=$(realpath ${data_dir}/kubeconfig)
kube_config_arg=--kubeconfig=${kubeconfig}
kubectl="kubectl ${kube_config_arg}"
tiller_namespace="kube-system"
helm_config_arg="${kube_config_arg} --tiller-namespace ${tiller_namespace}"
helm="helm ${helm_config_arg}"
terraform_dir=$(dirname $BASH_SOURCE)/cluster
terraform_plan=${data_dir}/terraform.plan

terraform_dir=$(realpath ${terraform_dir})
terraform_plan=$(realpath ${terraform_plan})

project_dir=$(realpath $(dirname $BASH_SOURCE)/../../..)
k8s_deploy_dir=$(realpath $(dirname $BASH_SOURCE))/deploy

kafka_topics=("BAI_APP_BFF" "BAI_APP_FETCHER" "BAI_APP_EXECUTOR" "BAI_SYS_BFF" "BAI_SYS_FETCHER" "BAI_SYS_EXECUTOR" "BAI_APP_STATUS" "CMD_SUBMIT" "CMD_RETURN")

readonly kubeflow_namespace=kubeflow

case "${object}" in
infra)

    case "${verb}" in
    create)
        create_infra $@
        ;;
    port-forward)
        port_forward $@
        ;;
    destroy)
        destroy_infra $@
        ;;
    get)
        get_infra $@
        ;;
    validate)
        validate_infra $@
        ;;
    *)
        print_unsupported_verb $object $verb
        ;;
    esac

    ;;
benchmark)

    case "${verb}" in
    run)
        run_benchmark $@
        ;;
    schedule)
        schedule_benchmark $@
        ;;
    get)
        get_benchmark $@
        ;;
    delete)
        delete_benchmark $@
        ;;
    list)
        list_benchmarks $@
        ;;
    *)
        print_unsupported_verb $object $verb
        ;;
    esac
    ;;

k8s-dashboard)

    case "${verb}" in
	show)
	    show_k8s_dashboard $@
	    ;;

	*)
        print_unsupported_verb $object $verb
        ;;
    esac
    ;;

*)
    printf "Unknown object"
    ;;
esac
