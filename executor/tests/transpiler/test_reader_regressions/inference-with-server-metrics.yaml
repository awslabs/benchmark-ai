#  Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.
#
#  Licensed under the Apache License, Version 2.0 (the "License").
#  You may not use this file except in compliance with the License.
#  A copy of the License is located at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  or in the "license" file accompanying this file. This file is distributed
#  on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either
#  express or implied. See the License for the specific language governing
#  permissions and limitations under the License.
apiVersion: batch/v1
kind: Job
metadata:
  name: benchmark-job-id
  labels:
    app: benchmark-ai
    action-id: ACTION_ID
    client-id: CLIENT_ID
    created-by: executor
spec:
  template:
    metadata:
      labels:
        app: benchmark-ai
        action-id: ACTION_ID
        client-id: CLIENT_ID
        created-by: executor
      annotations:
        iam.amazonaws.com/role: benchmark-host
    spec:
      serviceAccountName: inference-benchmark
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - benchmark-ai
            topologyKey: kubernetes.io/hostname
      initContainers:
      - name: data-puller
        image: benchmarkai/puller:3115770
        env:
        - name: S3_ENDPOINT
          valueFrom:
            configMapKeyRef:
              name: outputs-infrastructure
              key: s3_endpoint
        - name: AWS_ACCESS_KEY_ID
          valueFrom:
            configMapKeyRef:
              name: s3
              key: access-key-id
              optional: true
        - name: AWS_SECRET_ACCESS_KEY
          valueFrom:
            configMapKeyRef:
              name: s3
              key: secret-access-key
              optional: true
        volumeMounts:
        - name: datasets-volume
          mountPath: /data
        args:
        - puller-data
        - object-name/dir0,777,p0:object-name/dir1,777,p1
      - name: inference-server-lock
        image: benchmarkai/job-status-trigger:3115770
        env:
        - name: JOB_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: JOB_NAME
          value: is-benchmark-job-id
        - name: TRIGGER_STATUSES
          value: '[RUNNING_AT_MAIN_CONTAINERS]'
        - name: COMMAND
          value: exit 0
        - name: JOB_NOT_FOUND_GRACE_PERIOD_SECONDS
          value: '30'
      containers:
      - name: benchmark
        image: jlcont/benchmarking:270219
        resources:
          limits:
            nvidia.com/gpu: 0
        command:
        - python
        - /home/benchmark/benchmark_server.py
        - --host=${INFERENCE_SERVER_HOST}
        - --port=${INFERENCE_SERVER_PORT}
        - --request-timeout=5
        securityContext:
          privileged: false
        env:
        - name: BENCHMARK_AI
          value: fifo
        - name: BENCHMARK_AI_FIFO_FILEPATH
          value: /tmp/benchmark-ai/fifo
        - name: BENCHMARK_AI_FIFO_MAX_WAIT_TIME
          value: '60'
        - name: INFERENCE_SERVER_HOST
          value: is-benchmark-job-id.default
        - name: INFERENCE_SERVER_PORT
          value: '8080'
        - name: INFERENCE_SERVER_PORT_1
          value: '8081'
        volumeMounts:
        - mountPath: /tmp/benchmark-ai
          name: benchmark-ai
        - name: datasets-volume
          mountPath: ~/data/tf-imagenet/train
          subPath: p0
        - name: datasets-volume
          mountPath: ~/data/tf-imagenet/validation
          subPath: p1
        - name: dshm
          mountPath: /dev/shm
      nodeSelector:
        beta.kubernetes.io/instance-type: t3.medium
        node.type: bai-worker
        failure-domain.beta.kubernetes.io/zone: us-east-1a
      restartPolicy: OnFailure
      volumes:
      - name: benchmark-ai
        emptyDir: {}
      - name: datasets-volume
        emptyDir: {}
      - name: dshm
        emptyDir:
          medium: Memory
  backoffLimit: 4
---
apiVersion: v1
kind: Service
metadata:
  name: is-benchmark-job-id
  labels:
    action-id: ACTION_ID
    client-id: CLIENT_ID
    created-by: executor
spec:
  selector:
    inference-server-name: is-benchmark-job-id
  ports:
  - name: port-0
    protocol: TCP
    port: 8080
  - name: port-1
    protocol: TCP
    port: 8081
---
apiVersion: batch/v1
kind: Job
metadata:
  name: is-benchmark-job-id
  labels:
    app: benchmark-ai
    action-id: ACTION_ID
    client-id: CLIENT_ID
    created-by: executor
    inference-server-name: is-benchmark-job-id
spec:
  template:
    metadata:
      labels:
        app: benchmark-ai
        action-id: ACTION_ID
        client-id: CLIENT_ID
        created-by: executor
        inference-server-name: is-benchmark-job-id
      annotations:
        iam.amazonaws.com/role: benchmark-host
    spec:
      serviceAccountName: inference-benchmark
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - benchmark-ai
            topologyKey: kubernetes.io/hostname
      initContainers:
      - name: data-puller
        image: benchmarkai/puller:3115770
        env:
        - name: S3_ENDPOINT
          valueFrom:
            configMapKeyRef:
              name: outputs-infrastructure
              key: s3_endpoint
        - name: AWS_ACCESS_KEY_ID
          valueFrom:
            configMapKeyRef:
              name: s3
              key: access-key-id
              optional: true
        - name: AWS_SECRET_ACCESS_KEY
          valueFrom:
            configMapKeyRef:
              name: s3
              key: secret-access-key
              optional: true
        volumeMounts:
        - name: datasets-volume
          mountPath: /data
        args:
        - puller-data
        - object-name/dir0,777,p0:object-name/dir1,777,p1
      containers:
      - name: inference-server
        image: jlcont/server:270219
        resources:
          limits:
            nvidia.com/gpu: 4
        command:
        - /opt/bin/server
        - --model=mnist
        securityContext:
          privileged: false
        volumeMounts:
        - name: dshm
          mountPath: /dev/shm
        - name: datasets-volume
          mountPath: /path/to/model1
          subPath: p0
        - name: datasets-volume
          mountPath: /path/to/model2
          subPath: p1
        env:
        - name: VAR1
          value: value1
        - name: VAR2
          value: value2
        ports:
        - containerPort: 8080
        - containerPort: 8081
      - name: client-lock
        image: benchmarkai/job-status-trigger:3115770
        env:
        - name: JOB_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: JOB_NAME
          value: benchmark-job-id
        - name: TRIGGER_STATUSES
          value: '[SUCCEEDED, FAILED, JOB_NOT_FOUND]'
        - name: COMMAND
          value: /opt/env/bin/kubectl delete job,service is-benchmark-job-id
        - name: JOB_NOT_FOUND_GRACE_PERIOD_SECONDS
          value: '30'
        volumeMounts: []
      - name: metrics-pusher
        image: benchmarkai/metrics-pusher:ffed580
        env:
        - name: BENCHMARK_AI_FIFO_FILEPATH
          value: /tmp/benchmark-ai/fifo
        - name: BACKEND
          value: kafka
        - name: BACKEND_ARG_ACTION_ID
          value: ACTION_ID
        - name: BACKEND_ARG_CLIENT_ID
          value: CLIENT_ID
        - name: BACKEND_ARG_BOOTSTRAP_SERVERS
          valueFrom:
            configMapKeyRef:
              name: outputs-infrastructure
              key: msk_bootstrap_brokers
        - name: BACKEND_ARG_KEY
          value: CLIENT_ID
        - name: BACKEND_ARG_TOPIC
          value: BAI_METRICS
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        volumeMounts:
        - mountPath: /tmp/benchmark-ai
          name: benchmark-ai
      - name: metrics-extractor
        image: benchmarkai/metrics-extractor:b0b9185
        env:
        - name: ANUBIS_POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: ANUBIS_POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: ANUBIS_POD_CONTAINER
          value: inference-server
        - name: ANUBIS_METRICS
          value: '[{"name": "Requests2XX", "units": "requests", "pattern": "UmVxdWVzdHMyWFguY291bnQ6KFxkKyk="}]'
        - name: BENCHMARK_AI
          value: fifo
        - name: BENCHMARK_AI_FIFO_FILEPATH
          value: /tmp/benchmark-ai/fifo
        volumeMounts:
        - mountPath: /tmp/benchmark-ai
          name: benchmark-ai
      nodeSelector:
        beta.kubernetes.io/instance-type: p3.8xlarge
        node.type: bai-worker
        failure-domain.beta.kubernetes.io/zone: us-east-1c
      restartPolicy: OnFailure
      volumes:
      - name: benchmark-ai
        emptyDir: {}
      - name: datasets-volume
        emptyDir: {}
      - name: dshm
        emptyDir:
          medium: Memory
  backoffLimit: 4