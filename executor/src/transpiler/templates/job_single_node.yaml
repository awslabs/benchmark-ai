apiVersion: batch/v1
kind: Job
metadata:
  name: {job_id}
  labels:
    app: benchmark-ai
    action-id: {event.action_id}
    client-id: {event.client_id}
    created-by: {service_name}
spec:
  template:
    metadata:
      labels:
        app: benchmark-ai
        action-id: {event.action_id}
        client-id: {event.client_id}
        created-by: {service_name}
      annotations:
        iam.amazonaws.com/role: benchmark-host
    spec:
      # The service account used depends on whether
      # this is a benchmark or server pod
      # it is set programmatically by the transpiler
      serviceAccountName: TBD
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - benchmark-ai
            topologyKey: kubernetes.io/hostname
      initContainers:
      - name: data-puller
        image: {config.puller_docker_image}
        env:
        - name: S3_ENDPOINT
          valueFrom:
            configMapKeyRef:
              name: outputs-infrastructure
              key: s3_endpoint
        # This environment variables are optional.
        # They reference a config map missing in DEVO/PROD.
        # Enable the integration tests
        - name: AWS_ACCESS_KEY_ID
          valueFrom:
            configMapKeyRef:
              name: s3
              key: access-key-id
              optional: true
        - name: AWS_SECRET_ACCESS_KEY
          valueFrom:
            configMapKeyRef:
              name: s3
              key: secret-access-key
              optional: true
        volumeMounts:
        - name: datasets-volume
          mountPath: /data
      - name: script-puller
        image: {config.puller_docker_image}
        volumeMounts:
          - name: scripts-volume
            mountPath: /bai/scripts
        env:
        - name: S3_ENDPOINT
          valueFrom:
            configMapKeyRef:
              name: outputs-infrastructure
              key: s3_endpoint
        # This environment variables are optional.
        # They reference a config map missing in DEVO/PROD.
        # Enable the integration tests
        - name: AWS_ACCESS_KEY_ID
          valueFrom:
            configMapKeyRef:
              name: s3
              key: access-key-id
              optional: true
        - name: AWS_SECRET_ACCESS_KEY
          valueFrom:
            configMapKeyRef:
              name: s3
              key: secret-access-key
              optional: true
      # This container is only active
      # for inference benchmarks (when strategy is client-server)
      # It ensures the benchmark only starts after the inference server is running
      - name: inference-server-lock
        image: {config.job_status_trigger_docker_image}
        env:
          - name: JOB_NAMESPACE
            valueFrom:
              fieldRef:
                fieldPath: metadata.namespace
          - name: JOB_NAME
            value: {inference_server_job_id}
          - name: TRIGGER_STATUSES
            value: "[RUNNING_AT_MAIN_CONTAINERS]"
          - name: COMMAND
            value: 'exit 0'
          - name: JOB_NOT_FOUND_GRACE_PERIOD_SECONDS
            value: '30'
      containers:
      - name: benchmark
        image: {descriptor.env.docker_image}
        resources:
          limits:
            nvidia.com/gpu: {descriptor.hardware.gpus_per_instance}
        command: []
        args: []
        securityContext:
          privileged: {descriptor.env.privileged}
        env:
        - name: BENCHMARK_AI
          value: "fifo"
        - name: BENCHMARK_AI_FIFO_FILEPATH
          value: "/tmp/benchmark-ai/fifo"
        - name: BENCHMARK_AI_FIFO_MAX_WAIT_TIME
          value: "60"
        volumeMounts:
        - mountPath: /tmp/benchmark-ai
          name: benchmark-ai
        - mountPath: /bai/scripts
          name: scripts-volume
      - name: metrics-pusher
        image: {config.metrics_pusher_docker_image}
        env:
        - name: BENCHMARK_AI_FIFO_FILEPATH
          value: /tmp/benchmark-ai/fifo
        ##################################
        # Sidecar backend: Elasticsearch #
        ##################################
#        - name: BACKEND
#          value: elasticsearch
#        - name: BACKEND_ARG_ACTION_ID
#          value: {event.action_id}
#        - name: BACKEND_ARG_CLIENT_ID
#          value: {event.client_id}
#        - name: BACKEND_ARG_HOSTNAME
#          valueFrom:
#            configMapKeyRef:
#              name: outputs-infrastructure
#              key: es_endpoint
#        - name: BACKEND_ARG_PORT
#          value: "443"

        ##########################
        # Sidecar backend: Kafka #
        ##########################
        - name: BACKEND
          value: kafka
        - name: BACKEND_ARG_ACTION_ID
          value: {event.action_id}
        - name: BACKEND_ARG_CLIENT_ID
          value: {event.client_id}
        - name: BACKEND_ARG_BOOTSTRAP_SERVERS
          valueFrom:
            configMapKeyRef:
              name: outputs-infrastructure
              key: msk_bootstrap_brokers
        - name: BACKEND_ARG_KEY
          value: {event.client_id}
        - name: BACKEND_ARG_TOPIC
          value: BAI_METRICS
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        volumeMounts:
        - mountPath: /tmp/benchmark-ai
          name: benchmark-ai
      - name: metrics-extractor
        image: {config.metrics_extractor_docker_image}
        env:
        - name: ANUBIS_POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: ANUBIS_POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: ANUBIS_METRICS
          value: '{metrics}'
        - name: BENCHMARK_AI
          value: "fifo"
        - name: BENCHMARK_AI_FIFO_FILEPATH
          value: "/tmp/benchmark-ai/fifo"
        volumeMounts:
          - mountPath: /tmp/benchmark-ai
            name: benchmark-ai
      nodeSelector:
        beta.kubernetes.io/instance-type: {descriptor.hardware.instance_type}
        node.type: bai-worker
        failure-domain.beta.kubernetes.io/zone: {availability_zone}
      restartPolicy: OnFailure
      volumes:
      - name: benchmark-ai
        emptyDir: {{}}
      - name: datasets-volume
        emptyDir: {{}}
      - name: scripts-volume
        emptyDir: {{}}
  backoffLimit: 4
