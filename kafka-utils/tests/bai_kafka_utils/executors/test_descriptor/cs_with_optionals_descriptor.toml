[hardware]
instance_type = "t3.small"
strategy = "inference"

[env]
docker_image = "alpine"

# Server definition
[server]
# Harware on which to run the server
[server.hardware]
instance_type = "p3.8xlarge"
# The server environment definition
[server.env]
# The server image
docker_image = "jlcont/server:270219"
# Args for the docker container
# [Opt] Whether to run the container in privileged mode (default is false)
privileged = false
# [Opt - default is false] Whether more than 64MB shared memory is needed for containers
# (See docker's -shm option)
extended_shm = true
# array ports that are exposed by the server
ports = [8080, 8081]
# Server start command
start_command = ""
# [Opt] Arguments to pass to server start command
start_command_args = ""

# [Opt] Server readiness probe url
[server.env.readiness_probe]
# [Required] probe end point
path = "/ping"
# [Opt] uri scheme. One of [http, https]. Default: http
scheme = "http"
# [Opt] Will default to the first port defined in the [server.env] ports attribute
port = 8080
# [Opt] Number of seconds after server container starts to initiate probe (Default 10)
initial_delay_seconds = 10
# [Opt] How often to perform probe (Default 10)
period_seconds = 10
# [Opt] Number of seconds after which probe will timeout (Default 1)
timeout_seconds = 1
# [Opt] Minimum consecutive successes for probe to be considered successful (Default 1)
success_threshold = 1
# [Opt] Minimum consecutire failured for probe to be considered failed (Default 3)
failure_threshold = 3

# [Opt] Server environment variables
[server.env.vars]
VAR1 = "value1"
VAR2 = "value2"

[[server.models]]
src = "src1"
path = "path1"
md5 = "5d41402abc4b2a76b9719d911017c593"

[[server.models]]
id = "the2ndmodel"
src = "src2"
path = "path2"

[server.output]
[[server.output.metrics]]
name = "metric"
units = "unit"
pattern = "metric.unit:(\\d+)"
