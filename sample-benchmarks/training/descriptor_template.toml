# BenchmarkAI meta
spec_version = "0.1.0"

# These fields don't have any impact on the job to run, they contain
# merely informative data so the benchmark can be categorized when displayed
# in the dashboard.
[info]
task_name = "Title"
description = """ \
    Description of the job. Users might want to include details \
    such as whether it's inference or training, particular aspects \
    of their model, etc.\
    """

# 1. Hardware
[hardware]
instance_type = "p3.8xlarge"

# 2. Environment
[env]
# Docker hub <hub-user>/<repo-name>:<tag> 
docker_image = "jlcont/benchmarking:270219"
# Args for the docker container
# [Opt] Whether to run the container in privileged mode (default is false)
privileged = false
# [Opt] Whether more than 64MB shared memory is needed for containers
# (See docker's -shm option)
extended_shm = true

# 3. Machine learning related settings: 
# dataset, benchmark code and parameters it takes
[ml]
benchmark_code = "python /home/benchmark/image_classification.py"
# [Opt] Arguments to pass to the script in ml.benchmark_code
# The code is called as defined in ml.benchmark_code, plus the args defined here
args = "--model=resnet50_v2 --batch-size=32"

# [Opt] 4. Dataset 
[data]
# Dataset ID
id = "mnist"
# md5 = "rddytftyfrdr75657fftrtrt11"

# [Opt] Data sources
# List all required data sources below. 
# Make an entry for each with the same format as the ones below.
[[data.sources]]
# Data download URI.
uri = "s3://mlperf-data-stsukrov/imagenet/train-480px"
# [Not yet supported] Use this field to specify a preprocessing command.
# action = "unzip training_data.zip"
# Path where the dataset is stored in the container FS
path = "~/data/tf-imagenet/"

# Second data source
[[data.sources]]
# Data download URI.
uri = "s3://mlperf-data-stsukrov/imagenet/validation-480px"
# Path where the dataset is stored in the container FS
path = "~/data/tf-imagenet/"

# ...

# 4. Output
[output]
# Define which metrics will be tracked in this benchmark
metrics = ["throughput", "time"]
