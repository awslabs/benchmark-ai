# BenchmarkAI meta
spec_version = "0.1.0"

# These fields don't have any impact on the job to run, they contain
# merely informative data so the benchmark can be categorized when displayed
# in the dashboard.
[info]
task_name = "Title"
description = """ \
    Description of the job. Users might want to include details \
    such as whether it's inference or training, particular aspects \
    of their model, etc.\
    """

# 1. Hardware
[hardware]
instance_type = "p3.8xlarge"

# 2. Environment
[env]
# Docker hub <hub-user>/<repo-name>:<tag> 
docker_image = "jlcont/benchmarking:270219"
# Args for the docker container
# [Opt] Whether to run the container in privileged mode (default is false)
privileged = false

# 3. Machine learning related settings: 
# dataset, benchmark code and parameters it takes
[ml]
benchmark_code = "python /home/benchmark/image_classification.py"
# [Opt] Arguments to pass to the script in ml.benchmark_code
# The code is called as defined in ml.benchmark_code, plus the args defined here
args = "--model=resnet50_v2 --batch-size=32"

# [Opt] 4. Dataset 
[data]
# Dataset ID
dataset = "mnist"

# [Opt] Data sources
# List all required data sources below. 
# Make an entry for each with the same format as the ones below.
[[data.sources]]
# Data download script.
download = "python /home/benchmark/get_data.py mnist"
# [Opt] Use this field to specify any required preprocessing command.
action = "unzip training_data.zip"
# Path where the dataset is stored in the container FS
path = "/work/data/mnist/"

# Second data source
[[data.sources]]
# [Opt] Data download script.
download = "python /home/benchmark/get_data.py mnist"
# [Opt] Path where the dataset is stored in the container FS
path = "/work/data/mnist/"

# ...

# 4. Output
[output]
# Define which metrics will be tracked in this benchmark
metrics = ["throughput", "time"]
