# BenchmarkAI meta
spec_version = "0.1.0"

# These fields don't have any impact on the job to run, they contain
# merely informative data so the benchmark can be categorized when displayed
# in the dashboard.
[info]
task_name = "Example Horovod benchmark"
description = """ \
    An example benchmark using Horovod as distributed training strategy. \
    Running TensorFlow 1.13. \
    """

# 1. Hardware
[hardware]
instance_type = "p3.8xlarge"
strategy = "horovod"

# [Opt]
[hardware.distributed]
num_instances = 2

# 2. Environment
[env]
# Docker hub <hub-user>/<repo-name>:<tag> 
docker_image = "841569659894.dkr.ecr.us-east-1.amazonaws.com/testdockerpull:1.12-py3-gpu-with-horovod-build-for-bai"

# 3. Machine learning related settings: 
# dataset, benchmark code and parameters it takes
[ml]
benchmark_code = """
#!/bin/bash
echo 'ROLE' $ROLE
cp /etc/mpi/hostfile /root/hosts
cp /etc/mpi/hostfile /hosts
cp /etc/mpi/hostfile /deep-learning-models/models/resnet/tensorflow/hosts
chmod +x /deep-learning-models/models/resnet/tensorflow/train.sh
./deep-learning-models/models/resnet/tensorflow/train.sh 3
"""

# [Opt] 4. Dataset 
[data]
# Dataset ID
id = "imagenet"
# md5 = "rddytftyfrdr75657fftrtrt11"

# [Opt] Data sources
# List all required data sources below. 
# Make an entry for each with the same format as the ones below.
[[data.sources]]
# Data download URI.
src = "s3://mlperf-data-mxnet-berlin/imagenet/train-480px"
# Path where the dataset is stored in the container FS
path = "~/data/tf-imagenet/"

# Second data source
[[data.sources]]
# Data download URI.
src = "s3://mlperf-data-mxnet-berlin/imagenet/validation-480px"
# Path where the dataset is stored in the container FS
path = "~/data/tf-imagenet/"

